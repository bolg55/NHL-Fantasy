{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ad814db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Set up Chrome options\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "# Initialize the driver with the options\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Go to the website\n",
    "driver.get('https://www.spotrac.com/nhl/rankings/cap-hit/')\n",
    "\n",
    "# Scroll several times to load more data\n",
    "for _ in range(20):  # Adjust as needed\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Parse the loaded page with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "table = soup.find('table')\n",
    "\n",
    "# Define a CSV file to write the extracted data to\n",
    "with open('players_data.csv', 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    fieldnames = ['Player Name', 'Team', 'Position', 'Salary']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write the header\n",
    "    writer.writeheader()\n",
    "\n",
    "    rows = table.find_all('tr')\n",
    "    for row in rows[1:]:  # skipping the header row\n",
    "        tds = row.find_all('td')\n",
    "        if len(tds) != 4:  # if for some reason the row doesn't have 4 columns, we skip it\n",
    "            continue\n",
    "        \n",
    "        # Extracting player's name\n",
    "        player_name_element = tds[1].find('h3')\n",
    "        player_name = player_name_element.find('a').get_text(strip=True) if player_name_element else None\n",
    "\n",
    "        # Extracting player's team\n",
    "        team_img_element = tds[1].find('div', class_='rank-position').find('img')\n",
    "        team = team_img_element['src'].split('/')[-1].replace('.png', '').upper() if team_img_element else None\n",
    "\n",
    "        # Extracting player's position\n",
    "        position = tds[2].get_text(strip=True)\n",
    "\n",
    "        # Extracting player's salary\n",
    "        salary = tds[3].find('span', class_='info').get_text(strip=True)\n",
    "\n",
    "        writer.writerow({\n",
    "            'Player Name': player_name,\n",
    "            'Team': team,\n",
    "            'Position': position,\n",
    "            'Salary': salary\n",
    "        })\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
